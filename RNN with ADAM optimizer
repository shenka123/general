{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network (RNN) untuk data sekuensial\n",
    "### Modifikasi dengan Optimizer **ADAM**\n",
    "Benediktus Sashenka\n",
    "10117080\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *   \n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "#sb.set_theme()\n",
    "sb.set_style(\"whitegrid\")\n",
    "#sb.set_style(\"darkgrid\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(precision = 3, suppress = True, formatter = {'float':'{:6.5f}'.format})\n",
    "\n",
    "#Sigmoid function & its derivative\n",
    "sigmoid = lambda Z: 1/(1+exp(-Z))\n",
    "dsigmoid = lambda A: A*(1-A)\n",
    "\n",
    "#ReLU function & its derivative\n",
    "ReLU  = lambda Z: Z.clip(0)\n",
    "#Derivative of ReLU function\n",
    "dReLU = lambda A: (A > 0)*1\n",
    "\n",
    "#Derivativer of tanh()\n",
    "dtanh = lambda A: 1-A**2\n",
    "\n",
    "#Derivative oh arctanh\n",
    "darctanh = lambda A: 1/(A**2+1)\n",
    "\n",
    "#Softplus function & its derivative\n",
    "splus = lambda Z: log(1+exp(Z))\n",
    "dsplus = lambda A: 1/(1+exp(-A))\n",
    "\n",
    "linear = lambda X,w,b: X@w+b\n",
    "\n",
    "\"Time step (ts)\"\n",
    "def steps(x, step):   \n",
    "    obs  = len(x)-step\n",
    "    xt   = x[:obs,:]\n",
    "    for i in arange(1,step+1):\n",
    "        xt = hstack((xt, x[i:obs+i,:]))   \n",
    "    return xt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifikasi pada kelas RNN\n",
    "\n",
    "Sama seperti algoritma pada **SGD Dengan Momentum Nesterov (modifikasi dengan optimizer ADAM)**, modifikasi berada pada bagian updating parameter. Parameter yang ada pada algoritma RNN ini ada $W_0$, $b_0$, $W_1$, $b_1$, dan $W_s$ yang akan dibuat momen untuk masing-masing parameter tersebut untuk update parameter.\n",
    "\n",
    "Lalu karena sudah memakai momentum optimizer ADAM, learning rate yang digunakan tidak terlalu besar yaitu 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self,x,nh,alpha,epochs): # ada h nodes di dalam hidden layer  hlayers = [7, 3, 34, 89]\n",
    "        self.Xtrain  = x #input\n",
    "        self.ytrain  = x[:,-1:] #output     \n",
    "        self.nh = nh   #number of neurons in hidden layer\n",
    "        self.Î±  = alpha\n",
    "        self.epochs = epochs\n",
    "        self.Ts = shape(self.Xtrain)[1]-1   # Time-steps\n",
    "        self.N, no = shape(self.ytrain)     #jumlah observasi (self.N) dan jumlah output\n",
    "        self.ni    = 1  #jumlah input\n",
    "        \n",
    "        \"Initial values untuk parameter w and b\"\n",
    "        seed(20201212)\n",
    "        self.w0 = randn(self.ni,self.nh)\n",
    "        self.b0 = randn(1,self.nh)\n",
    "        self.w1 = randn(self.nh,no)\n",
    "        self.b1 = randn(1,no)\n",
    "        self.ws = randn(self.nh,self.nh)\n",
    "        \n",
    "        \"Initial values untuk momen dengan random, momen v harus positif\"\n",
    "        self.mw0 = randn(self.ni,self.nh)\n",
    "        self.mb0 = randn(1,self.nh)\n",
    "        self.mw1 = randn(self.nh,no)\n",
    "        self.mb1 = randn(1,no)\n",
    "        self.mws = randn(self.nh,self.nh)\n",
    "        \n",
    "        self.vw0 = randn(self.ni,self.nh)**2\n",
    "        self.vb0 = randn(1,self.nh)**2\n",
    "        self.vw1 = randn(self.nh,no)**2\n",
    "        self.vb1 = randn(1,no)**2\n",
    "        self.vws = randn(self.nh,self.nh)**2\n",
    "        \n",
    "    def learning(self):\n",
    "        self.ycap = []\n",
    "        for i in range(len(self.Xtrain)):\n",
    "            self.S1 = [zeros((self.ni, self.nh))]  \n",
    "            self.S2 = []              \n",
    "            dCdw0 = zeros_like(self.w0)\n",
    "            dCdb0 = zeros_like(self.b0)\n",
    "            dCdw1 = zeros_like(self.w1)\n",
    "            dCdb1 = zeros_like(self.b1)\n",
    "            dCdws = zeros_like(self.ws)\n",
    "            \n",
    "            \"Forward propagation in time step\"\n",
    "            for k in range(self.Ts):       \n",
    "                A0 = self.Xtrain[i,k]\n",
    "                yk = self.Xtrain[i,k + 1]\n",
    "            \n",
    "                # Forward pass, 1st layer\n",
    "                Z1 = dot(A0,self.w0) + self.b0 + (self.S1[-1]@self.ws) \n",
    "                A1 = tanh(Z1)\n",
    "                self.S1.append(copy(A1))   \n",
    "            \n",
    "                # Forward pass, 2nd layer\n",
    "                Z2 = A1@self.w1 + self.b1\n",
    "                A2 = sigmoid(Z2)\n",
    "                self.S2.append(copy(A2))\n",
    "                \n",
    "            self.ycap.append(A2[0])\n",
    "            \n",
    "            \"Backward propagation in time step\"\n",
    "            for k in arange(self.Ts)[::-1]:     \n",
    "                A0 = self.Xtrain[i,k]\n",
    "                yk = self.Xtrain[i,k + 1]\n",
    "            \n",
    "                # Backprop, 2nd layer\n",
    "                dCdZ2 = -(yk - self.S2[k]) * dsigmoid(self.S2[k])\n",
    "                dCdw1 += dot(self.S1[k+1].T,dCdZ2)\n",
    "                dCdb1 += sum(dCdZ2)\n",
    "            \n",
    "                # Backprop, 1st layer\n",
    "                dCdZ1 = dCdZ2@self.w1.T * dtanh(self.S1[k+1])\n",
    "                dCdw0 += dot(A0, dCdZ1)\n",
    "                dCdb0 += sum(dCdZ1)\n",
    "            \n",
    "                # Backprob, recurrent layer\n",
    "                dCdws += dot(self.S1[k].T, dCdZ1)\n",
    "                \n",
    "            \n",
    "            \"_____________________ MODIFIKASI DENGAN ADAM _____________________\"\n",
    "            \n",
    "            \"Parameter ADAM\"\n",
    "            \n",
    "            t     = i\n",
    "            beta1 = 0.9\n",
    "            beta2 = 0.999\n",
    "            eps   = 1E-8\n",
    "            \n",
    "            \"Menghitung estimator momen m dan v\"\n",
    "            self.mw0 = beta1*self.mw0 + (1-beta1)*dCdw0\n",
    "            self.mb0 = beta1*self.mb0 + (1-beta1)*dCdb0\n",
    "            self.mw1 = beta1*self.mw1 + (1-beta1)*dCdw1\n",
    "            self.mb1 = beta1*self.mb1 + (1-beta1)*dCdb1\n",
    "            self.mws = beta1*self.mws + (1-beta1)*dCdws\n",
    "            \n",
    "            self.vw0 = beta2*self.vw0 + (1-beta2)*(dCdw0**2)\n",
    "            self.vb0 = beta2*self.vb0 + (1-beta2)*(dCdb0**2)\n",
    "            self.vw1 = beta2*self.vw1 + (1-beta2)*(dCdw1**2)\n",
    "            self.vb1 = beta2*self.vb1 + (1-beta2)*(dCdb1**2)\n",
    "            self.vws = beta2*self.vws + (1-beta2)*(dCdws**2)\n",
    "                \n",
    "            \"Menghilangkan kebiasan m dan v\"\n",
    "            \n",
    "            mw0_est = self.mw0/(1-beta1**(t+1))\n",
    "            mb0_est = self.mb0/(1-beta1**(t+1))\n",
    "            mw1_est = self.mw1/(1-beta1**(t+1))\n",
    "            mb1_est = self.mb1/(1-beta1**(t+1))\n",
    "            mws_est = self.mws/(1-beta1**(t+1))\n",
    "            \n",
    "            vw0_est = self.vw0/(1-beta2**(t+1))\n",
    "            vb0_est = self.vb0/(1-beta2**(t+1))\n",
    "            vw1_est = self.vw1/(1-beta2**(t+1))\n",
    "            vb1_est = self.vb1/(1-beta2**(t+1))\n",
    "            vws_est = self.vws/(1-beta2**(t+1))\n",
    "                \n",
    "            \"Updating parameter W dan b\"\n",
    "            \n",
    "            self.w0 -= (alpha/(np.sqrt(vw0_est)+eps))*mw0_est\n",
    "            self.b0 -= (alpha/(np.sqrt(vb0_est)+eps))*mb0_est\n",
    "            self.w1 -= (alpha/(np.sqrt(vw1_est)+eps))*mw1_est\n",
    "            self.b1 -= (alpha/(np.sqrt(vb1_est)+eps))*mb1_est\n",
    "            self.ws -= (alpha/(np.sqrt(vws_est)+eps))*mws_est\n",
    "                \n",
    "                \n",
    "            \"_____________________ MODIFIKASI DENGAN ADAM _____________________\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pemakaian RNN untuk penaksiran harga saham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A  = pd.read_csv('ASII_10117080.csv')  #Data time series harian harga saham ASII\n",
    "A['Adj Close'].fillna(A['Adj Close'].mean(), inplace=True)\n",
    "A6 = np.array(A['Adj Close'])\n",
    "B  = A6[:,newaxis]  #berupa matriks\n",
    "\n",
    "Bmin = min(B)\n",
    "Bmax = max(B)\n",
    "b = (B-Bmin)/(Bmax-Bmin)\n",
    "\n",
    "ts = 1   #Di literatur Time Series digunakan istilah 'lag' sebagai padanan istilah 'timestep' ini\n",
    "xs = steps(b, ts)  #Dihasilkan matriks dengan 2 (= ts+1) kolom, kolom pertama menjadi variabel X\n",
    "                   #dan kolom terkhir menjadi variabel \n",
    "x = xs[-800:,:]    #Ambil 800 observasi terakhir\n",
    "\n",
    "#Data untuk training\n",
    "Xtrain = x[0:680,:]   #Ambil 680 observasi yang pertama dan hilangkan kolom terakhir\n",
    "ytrain = x[0:680:, -1:]  #Ambil 680 observasi yang pertama dan ambil kolom terakhir sebagai variabel y \n",
    "\n",
    "#Data untuk testing\n",
    "Xtest = x[680:, :]   #ambil jumlah observasi sebanyak 120, hilangkan kolom terakhir (untuk y)\n",
    "ytest = x[680:, -1:] #ambil kolom terakhir\n",
    "\n",
    "#plt.plot(Xtrain, color = 'b')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch ke 0, SSE sebesar: 0.31133 dalam waktu 0:00:00.913936\n"
     ]
    }
   ],
   "source": [
    "nh     = 3  \n",
    "alpha  = 0.001\n",
    "epochs = 51\n",
    "\n",
    "\"Training\"\n",
    "\n",
    "rnn2 = RNN(Xtrain,nh,alpha,epochs)\n",
    "tic = datetime.now()\n",
    "\n",
    "for n in range(epochs):\n",
    "    rnn2.learning()\n",
    "    e = rnn2.ycap - ytrain\n",
    "    sse = dot(e.T,e)/len(ytrain)\n",
    "    toc = datetime.now()\n",
    "            \n",
    "    if n % ((epochs-1)/5) == 0:\n",
    "        #print(f\"\\nPada epoch ke {n} diperoleh predicted vs actual:\")\n",
    "        #print(hstack((array(rnn2.ycap), ytrain.reshape(4,1))))\n",
    "        print(f\"Epoch ke {n}, SSE sebesar: {sse[0][0]:6.5f} dalam waktu {datetime.now()-tic}\")\n",
    "\n",
    "#rnn = RNN(Xtrain,nh,alpha,epochs)\n",
    "#rnn.training()\n",
    "\n",
    "plt.plot(ytrain, label = 'actual series')\n",
    "plt.plot(rnn2.ycap, label = 'predicted series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytestcap = []\n",
    "\n",
    "for i in range(len(Xtest)):\n",
    "    S1 = [zeros((1, nh))]  \n",
    "    S2 = []              \n",
    "            \n",
    "    \"Forward propagation in time step\"\n",
    "    for k in range(rnn2.Ts):       \n",
    "        A0 = Xtest[i,k]\n",
    "        yk = Xtest[i,k + 1]\n",
    "            \n",
    "        # Forward pass, 1st layer\n",
    "        Z1 = dot(A0,rnn2.w0) + rnn2.b0 + (S1[-1]@rnn2.ws) \n",
    "        A1 = tanh(Z1)\n",
    "        S1.append(copy(A1))   \n",
    "            \n",
    "        # Forward pass, 2nd layer\n",
    "        Z2 = A1@rnn2.w1 + rnn2.b1\n",
    "        A2 = sigmoid(Z2)\n",
    "        rnn2.S2.append(copy(A2))\n",
    "                \n",
    "    ytestcap.append(A2[0])\n",
    "\n",
    "e = ytestcap - ytest\n",
    "ssetest = dot(e.T,e)/len(ytest)\n",
    "print('MSE training: %8.7f'%sse,'\\nMSE testing : %7.7f'%ssetest)\n",
    "      \n",
    "plt.plot(ytest, label = 'actual series')\n",
    "plt.plot(ytestcap, label = 'predicted series')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
